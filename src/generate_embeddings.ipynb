{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "1. Import dataset \n",
    "2. Create embeddings for queries in the train set\n",
    "3. Train an MLP to route queries to LLMs based on the corresponding model performance scores\n",
    "4. Use the embedding finetune pipeline to route queries instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shloknatarajan/stanford/329a/encoder-testing/.pixi/envs/default/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompted_question', 'answer', 'category', 'model_performance'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompted_question', 'answer', 'category', 'model_performance'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_data.export_data import get_processed_dataset\n",
    "data = get_processed_dataset()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions = data['train']['prompted_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = data['test']['prompted_question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-01 15:11:16.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mencoder.models.modernBERT\u001b[0m:\u001b[36mget_modernbert_embeddings\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mGenerating embeddings for 450 queries\u001b[0m\n",
      "Generating embeddings: 100%|██████████| 57/57 [01:47<00:00,  1.89s/it]\n",
      "\u001b[32m2025-04-01 15:13:04.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mencoder.models.modernBERT\u001b[0m:\u001b[36mget_modernbert_embeddings\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mGenerating embeddings for 50 queries\u001b[0m\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from encoder.models.modernBERT import get_modernbert_embeddings\n",
    "train_embeddings = get_modernbert_embeddings(train_questions)\n",
    "test_embeddings = get_modernbert_embeddings(test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = data['train']['model_performance']\n",
    "test_metrics = data['test']['model_performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an MLP to route queries to LLMs based on the corresponding model performance scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
